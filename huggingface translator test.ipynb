{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.35.2)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.1.99)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (15.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2023.9.0,>=2023.1.0->datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers sentencepiece datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import sentencepiece\n",
    "import datasets\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import itertools\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AdamW, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe want to use  mt5-base\n",
    "model_repo = 'google/mt5-small'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the pretrained tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "225b4f70aaa04270a54454310d5fd770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/82.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "307afd20c0de49eaa5786d2081375186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/553 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672daf2e51354fc394ace1ef2e9f5fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19022a061e6e4d4a9eba621bf784630b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa5d834842c4e6b9db2ba29cd7290b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66611d8aa990480594441c02b82e7666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# download mt5 tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_repo)\n",
    "# download model\n",
    "model= AutoModelForSeq2SeqLM.from_pretrained(model_repo)\n",
    "# puts model onto GPU\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  714,   339,   259,   262,   259, 98923,     1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# initalize test sentence\n",
    "input = 'this is a sentence'\n",
    "# tokenize sentence, convert to tensor, and put onto GPU\n",
    "token_ids = tokenizer.encode(input, return_tensors='pt').cuda()\n",
    "# show tokenized sentence\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> <extra_id_0></s>\n"
     ]
    }
   ],
   "source": [
    "# put input through model\n",
    "output = model.generate(token_ids)\n",
    "# convert output to tokens and then to string\n",
    "output_str = tokenizer.convert_tokens_to_string(\n",
    "    tokenizer.convert_ids_to_tokens(output[0])\n",
    "    )\n",
    "print(output_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1042,   263,   325,   669,   714,   568,   263,   259,   262,   259,\n",
      "         98923,   742,   263,   285,  2547,     1]], device='cuda:0')\n",
      "['▁<', 's', 'p', '>', '▁this', '▁ni', 's', '▁', 'a', '▁', 'sentence', '▁f', 's', 'd', 'ff', '</s>']\n"
     ]
    }
   ],
   "source": [
    "example_input = '<sp> this nis a sentence fsdff'\n",
    "input_ids = tokenizer.encode(example_input, return_tensors='pt').cuda()\n",
    "print(input_ids)\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<pad>', 0),\n",
       " ('</s>', 1),\n",
       " ('<unk>', 2),\n",
       " ('<0x00>', 3),\n",
       " ('<0x01>', 4),\n",
       " ('<0x02>', 5),\n",
       " ('<0x03>', 6),\n",
       " ('<0x04>', 7),\n",
       " ('<0x05>', 8),\n",
       " ('<0x06>', 9),\n",
       " ('<0x07>', 10),\n",
       " ('<0x08>', 11),\n",
       " ('<0x09>', 12),\n",
       " ('<0x0A>', 13),\n",
       " ('<0x0B>', 14),\n",
       " ('<0x0C>', 15),\n",
       " ('<0x0D>', 16),\n",
       " ('<0x0E>', 17),\n",
       " ('<0x0F>', 18),\n",
       " ('<0x10>', 19),\n",
       " ('<0x11>', 20),\n",
       " ('<0x12>', 21),\n",
       " ('<0x13>', 22),\n",
       " ('<0x14>', 23),\n",
       " ('<0x15>', 24),\n",
       " ('<0x16>', 25),\n",
       " ('<0x17>', 26),\n",
       " ('<0x18>', 27),\n",
       " ('<0x19>', 28),\n",
       " ('<0x1A>', 29),\n",
       " ('<0x1B>', 30),\n",
       " ('<0x1C>', 31),\n",
       " ('<0x1D>', 32),\n",
       " ('<0x1E>', 33),\n",
       " ('<0x1F>', 34),\n",
       " ('<0x20>', 35),\n",
       " ('<0x21>', 36),\n",
       " ('<0x22>', 37),\n",
       " ('<0x23>', 38),\n",
       " ('<0x24>', 39),\n",
       " ('<0x25>', 40),\n",
       " ('<0x26>', 41),\n",
       " ('<0x27>', 42),\n",
       " ('<0x28>', 43),\n",
       " ('<0x29>', 44),\n",
       " ('<0x2A>', 45),\n",
       " ('<0x2B>', 46),\n",
       " ('<0x2C>', 47),\n",
       " ('<0x2D>', 48),\n",
       " ('<0x2E>', 49),\n",
       " ('<0x2F>', 50),\n",
       " ('<0x30>', 51),\n",
       " ('<0x31>', 52),\n",
       " ('<0x32>', 53),\n",
       " ('<0x33>', 54),\n",
       " ('<0x34>', 55),\n",
       " ('<0x35>', 56),\n",
       " ('<0x36>', 57),\n",
       " ('<0x37>', 58),\n",
       " ('<0x38>', 59),\n",
       " ('<0x39>', 60),\n",
       " ('<0x3A>', 61),\n",
       " ('<0x3B>', 62),\n",
       " ('<0x3C>', 63),\n",
       " ('<0x3D>', 64),\n",
       " ('<0x3E>', 65),\n",
       " ('<0x3F>', 66),\n",
       " ('<0x40>', 67),\n",
       " ('<0x41>', 68),\n",
       " ('<0x42>', 69),\n",
       " ('<0x43>', 70),\n",
       " ('<0x44>', 71),\n",
       " ('<0x45>', 72),\n",
       " ('<0x46>', 73),\n",
       " ('<0x47>', 74),\n",
       " ('<0x48>', 75),\n",
       " ('<0x49>', 76),\n",
       " ('<0x4A>', 77),\n",
       " ('<0x4B>', 78),\n",
       " ('<0x4C>', 79),\n",
       " ('<0x4D>', 80),\n",
       " ('<0x4E>', 81),\n",
       " ('<0x4F>', 82),\n",
       " ('<0x50>', 83),\n",
       " ('<0x51>', 84),\n",
       " ('<0x52>', 85),\n",
       " ('<0x53>', 86),\n",
       " ('<0x54>', 87),\n",
       " ('<0x55>', 88),\n",
       " ('<0x56>', 89),\n",
       " ('<0x57>', 90),\n",
       " ('<0x58>', 91),\n",
       " ('<0x59>', 92),\n",
       " ('<0x5A>', 93),\n",
       " ('<0x5B>', 94),\n",
       " ('<0x5C>', 95),\n",
       " ('<0x5D>', 96),\n",
       " ('<0x5E>', 97),\n",
       " ('<0x5F>', 98),\n",
       " ('<0x60>', 99),\n",
       " ('<0x61>', 100),\n",
       " ('<0x62>', 101),\n",
       " ('<0x63>', 102),\n",
       " ('<0x64>', 103),\n",
       " ('<0x65>', 104),\n",
       " ('<0x66>', 105),\n",
       " ('<0x67>', 106),\n",
       " ('<0x68>', 107),\n",
       " ('<0x69>', 108),\n",
       " ('<0x6A>', 109),\n",
       " ('<0x6B>', 110),\n",
       " ('<0x6C>', 111),\n",
       " ('<0x6D>', 112),\n",
       " ('<0x6E>', 113),\n",
       " ('<0x6F>', 114),\n",
       " ('<0x70>', 115),\n",
       " ('<0x71>', 116),\n",
       " ('<0x72>', 117),\n",
       " ('<0x73>', 118),\n",
       " ('<0x74>', 119),\n",
       " ('<0x75>', 120),\n",
       " ('<0x76>', 121),\n",
       " ('<0x77>', 122),\n",
       " ('<0x78>', 123),\n",
       " ('<0x79>', 124),\n",
       " ('<0x7A>', 125),\n",
       " ('<0x7B>', 126),\n",
       " ('<0x7C>', 127),\n",
       " ('<0x7D>', 128),\n",
       " ('<0x7E>', 129),\n",
       " ('<0x7F>', 130),\n",
       " ('<0x80>', 131),\n",
       " ('<0x81>', 132),\n",
       " ('<0x82>', 133),\n",
       " ('<0x83>', 134),\n",
       " ('<0x84>', 135),\n",
       " ('<0x85>', 136),\n",
       " ('<0x86>', 137),\n",
       " ('<0x87>', 138),\n",
       " ('<0x88>', 139),\n",
       " ('<0x89>', 140),\n",
       " ('<0x8A>', 141),\n",
       " ('<0x8B>', 142),\n",
       " ('<0x8C>', 143),\n",
       " ('<0x8D>', 144),\n",
       " ('<0x8E>', 145),\n",
       " ('<0x8F>', 146),\n",
       " ('<0x90>', 147),\n",
       " ('<0x91>', 148),\n",
       " ('<0x92>', 149),\n",
       " ('<0x93>', 150),\n",
       " ('<0x94>', 151),\n",
       " ('<0x95>', 152),\n",
       " ('<0x96>', 153),\n",
       " ('<0x97>', 154),\n",
       " ('<0x98>', 155),\n",
       " ('<0x99>', 156),\n",
       " ('<0x9A>', 157),\n",
       " ('<0x9B>', 158),\n",
       " ('<0x9C>', 159),\n",
       " ('<0x9D>', 160),\n",
       " ('<0x9E>', 161),\n",
       " ('<0x9F>', 162),\n",
       " ('<0xA0>', 163),\n",
       " ('<0xA1>', 164),\n",
       " ('<0xA2>', 165),\n",
       " ('<0xA3>', 166),\n",
       " ('<0xA4>', 167),\n",
       " ('<0xA5>', 168),\n",
       " ('<0xA6>', 169),\n",
       " ('<0xA7>', 170),\n",
       " ('<0xA8>', 171),\n",
       " ('<0xA9>', 172),\n",
       " ('<0xAA>', 173),\n",
       " ('<0xAB>', 174),\n",
       " ('<0xAC>', 175),\n",
       " ('<0xAD>', 176),\n",
       " ('<0xAE>', 177),\n",
       " ('<0xAF>', 178),\n",
       " ('<0xB0>', 179),\n",
       " ('<0xB1>', 180),\n",
       " ('<0xB2>', 181),\n",
       " ('<0xB3>', 182),\n",
       " ('<0xB4>', 183),\n",
       " ('<0xB5>', 184),\n",
       " ('<0xB6>', 185),\n",
       " ('<0xB7>', 186),\n",
       " ('<0xB8>', 187),\n",
       " ('<0xB9>', 188),\n",
       " ('<0xBA>', 189),\n",
       " ('<0xBB>', 190),\n",
       " ('<0xBC>', 191),\n",
       " ('<0xBD>', 192),\n",
       " ('<0xBE>', 193),\n",
       " ('<0xBF>', 194),\n",
       " ('<0xC0>', 195),\n",
       " ('<0xC1>', 196),\n",
       " ('<0xC2>', 197),\n",
       " ('<0xC3>', 198),\n",
       " ('<0xC4>', 199),\n",
       " ('<0xC5>', 200),\n",
       " ('<0xC6>', 201),\n",
       " ('<0xC7>', 202),\n",
       " ('<0xC8>', 203),\n",
       " ('<0xC9>', 204),\n",
       " ('<0xCA>', 205),\n",
       " ('<0xCB>', 206),\n",
       " ('<0xCC>', 207),\n",
       " ('<0xCD>', 208),\n",
       " ('<0xCE>', 209),\n",
       " ('<0xCF>', 210),\n",
       " ('<0xD0>', 211),\n",
       " ('<0xD1>', 212),\n",
       " ('<0xD2>', 213),\n",
       " ('<0xD3>', 214),\n",
       " ('<0xD4>', 215),\n",
       " ('<0xD5>', 216),\n",
       " ('<0xD6>', 217),\n",
       " ('<0xD7>', 218),\n",
       " ('<0xD8>', 219),\n",
       " ('<0xD9>', 220),\n",
       " ('<0xDA>', 221),\n",
       " ('<0xDB>', 222),\n",
       " ('<0xDC>', 223),\n",
       " ('<0xDD>', 224),\n",
       " ('<0xDE>', 225),\n",
       " ('<0xDF>', 226),\n",
       " ('<0xE0>', 227),\n",
       " ('<0xE1>', 228),\n",
       " ('<0xE2>', 229),\n",
       " ('<0xE3>', 230),\n",
       " ('<0xE4>', 231),\n",
       " ('<0xE5>', 232),\n",
       " ('<0xE6>', 233),\n",
       " ('<0xE7>', 234),\n",
       " ('<0xE8>', 235),\n",
       " ('<0xE9>', 236),\n",
       " ('<0xEA>', 237),\n",
       " ('<0xEB>', 238),\n",
       " ('<0xEC>', 239),\n",
       " ('<0xED>', 240),\n",
       " ('<0xEE>', 241),\n",
       " ('<0xEF>', 242),\n",
       " ('<0xF0>', 243),\n",
       " ('<0xF1>', 244),\n",
       " ('<0xF2>', 245),\n",
       " ('<0xF3>', 246),\n",
       " ('<0xF4>', 247),\n",
       " ('<0xF5>', 248),\n",
       " ('<0xF6>', 249),\n",
       " ('<0xF7>', 250),\n",
       " ('<0xF8>', 251),\n",
       " ('<0xF9>', 252),\n",
       " ('<0xFA>', 253),\n",
       " ('<0xFB>', 254),\n",
       " ('<0xFC>', 255),\n",
       " ('<0xFD>', 256),\n",
       " ('<0xFE>', 257),\n",
       " ('<0xFF>', 258),\n",
       " ('▁', 259),\n",
       " ('.', 260),\n",
       " (',', 261),\n",
       " ('a', 262),\n",
       " ('s', 263),\n",
       " ('-', 264),\n",
       " ('e', 265),\n",
       " ('i', 266),\n",
       " (':', 267),\n",
       " ('o', 268),\n",
       " ('▁de', 269),\n",
       " ('t', 270),\n",
       " (')', 271),\n",
       " ('n', 272),\n",
       " ('u', 273),\n",
       " ('▁(', 274),\n",
       " ('/', 275),\n",
       " ('y', 276),\n",
       " (\"'\", 277),\n",
       " ('en', 278),\n",
       " ('и', 279),\n",
       " ('l', 280),\n",
       " ('▁in', 281),\n",
       " ('m', 282),\n",
       " ('▁la', 283),\n",
       " ('com', 284),\n",
       " ('d', 285),\n",
       " ('r', 286),\n",
       " ('▁the', 287),\n",
       " ('▁to', 288),\n",
       " ('▁en', 289),\n",
       " ('_', 290),\n",
       " ('?', 291),\n",
       " ('、', 292),\n",
       " ('’', 293),\n",
       " ('▁na', 294),\n",
       " ('er', 295),\n",
       " (';', 296),\n",
       " ('c', 297),\n",
       " ('▁A', 298),\n",
       " ('es', 299),\n",
       " ('▁v', 300),\n",
       " ('▁di', 301),\n",
       " ('...', 302),\n",
       " ('▁se', 303),\n",
       " ('▁of', 304),\n",
       " ('▁and', 305),\n",
       " ('。', 306),\n",
       " ('▁|', 307),\n",
       " ('а', 308),\n",
       " ('!', 309),\n",
       " ('▁на', 310),\n",
       " ('\"', 311),\n",
       " ('(', 312),\n",
       " ('▁\"', 313),\n",
       " ('k', 314),\n",
       " ('▁в', 315),\n",
       " ('b', 316),\n",
       " ('▁c', 317),\n",
       " ('g', 318),\n",
       " ('▁que', 319),\n",
       " ('▁S', 320),\n",
       " ('an', 321),\n",
       " ('▁–', 322),\n",
       " ('▁www', 323),\n",
       " ('е', 324),\n",
       " ('p', 325),\n",
       " ('▁m', 326),\n",
       " ('▁sa', 327),\n",
       " ('3', 328),\n",
       " ('x', 329),\n",
       " ('▁b', 330),\n",
       " ('▁d', 331),\n",
       " ('▁for', 332),\n",
       " ('▁1', 333),\n",
       " ('h', 334),\n",
       " ('▁un', 335),\n",
       " ('▁I', 336),\n",
       " ('os', 337),\n",
       " ('2', 338),\n",
       " ('▁is', 339),\n",
       " ('▁le', 340),\n",
       " ('▁و', 341),\n",
       " ('▁do', 342),\n",
       " ('،', 343),\n",
       " ('▁at', 344),\n",
       " ('ed', 345),\n",
       " ('te', 346),\n",
       " ('ing', 347),\n",
       " ('in', 348),\n",
       " ('=', 349),\n",
       " ('▁da', 350),\n",
       " ('▁on', 351),\n",
       " ('▁M', 352),\n",
       " ('1', 353),\n",
       " ('у', 354),\n",
       " ('▁đ', 355),\n",
       " ('▁2', 356),\n",
       " ('A', 357),\n",
       " ('as', 358),\n",
       " ('▁“', 359),\n",
       " ('z', 360),\n",
       " ('é', 361),\n",
       " ('▁el', 362),\n",
       " ('▁P', 363),\n",
       " ('▁B', 364),\n",
       " ('”', 365),\n",
       " ('▁T', 366),\n",
       " ('f', 367),\n",
       " ('de', 368),\n",
       " ('à', 369),\n",
       " ('ng', 370),\n",
       " ('▁C', 371),\n",
       " ('ar', 372),\n",
       " ('▁og', 373),\n",
       " ('▁за', 374),\n",
       " ('▁no', 375),\n",
       " ('ه', 376),\n",
       " ('na', 377),\n",
       " ('।', 378),\n",
       " ('v', 379),\n",
       " ('re', 380),\n",
       " ('▁3', 381),\n",
       " ('▁h', 382),\n",
       " ('▁et', 383),\n",
       " ('▁je', 384),\n",
       " ('j', 385),\n",
       " ('▁il', 386),\n",
       " ('▁#', 387),\n",
       " ('▁с', 388),\n",
       " ('і', 389),\n",
       " ('▁be', 390),\n",
       " ('://', 391),\n",
       " ('▁2018', 392),\n",
       " ('▁per', 393),\n",
       " ('▁th', 394),\n",
       " ('▁si', 395),\n",
       " ('я', 396),\n",
       " ('▁z', 397),\n",
       " ('▁die', 398),\n",
       " ('S', 399),\n",
       " ('▁te', 400),\n",
       " ('▁не', 401),\n",
       " ('▁ال', 402),\n",
       " ('D', 403),\n",
       " ('▁«', 404),\n",
       " ('ne', 405),\n",
       " ('ی', 406),\n",
       " ('da', 407),\n",
       " ('▁k', 408),\n",
       " ('|', 409),\n",
       " ('4', 410),\n",
       " ('о', 411),\n",
       " ('▁K', 412),\n",
       " ('▁du', 413),\n",
       " ('▁w', 414),\n",
       " ('▁E', 415),\n",
       " ('▁me', 416),\n",
       " ('is', 417),\n",
       " ('▁are', 418),\n",
       " ('▁4', 419),\n",
       " ('í', 420),\n",
       " ('▁p', 421),\n",
       " ('ta', 422),\n",
       " ('の', 423),\n",
       " ('C', 424),\n",
       " ('▁по', 425),\n",
       " ('▁del', 426),\n",
       " ('▁ka', 427),\n",
       " ('5', 428),\n",
       " ('et', 429),\n",
       " ('▁5', 430),\n",
       " ('▁D', 431),\n",
       " ('▁ja', 432),\n",
       " ('ы', 433),\n",
       " ('▁V', 434),\n",
       " ('▁para', 435),\n",
       " ('»', 436),\n",
       " ('\",\"', 437),\n",
       " ('us', 438),\n",
       " (']', 439),\n",
       " ('▁al', 440),\n",
       " ('▁N', 441),\n",
       " ('▁der', 442),\n",
       " ('▁O', 443),\n",
       " ('on', 444),\n",
       " ('ة', 445),\n",
       " ('▁да', 446),\n",
       " ('▁H', 447),\n",
       " ('▁ne', 448),\n",
       " ('8', 449),\n",
       " ('▁con', 450),\n",
       " ('6', 451),\n",
       " ('B', 452),\n",
       " ('▁er', 453),\n",
       " ('ul', 454),\n",
       " ('▁by', 455),\n",
       " ('▁у', 456),\n",
       " ('▁yang', 457),\n",
       " ('▁L', 458),\n",
       " ('▁De', 459),\n",
       " ('0', 460),\n",
       " ('▁an', 461),\n",
       " ('ja', 462),\n",
       " ('\\xad', 463),\n",
       " ('▁van', 464),\n",
       " ('▁ה', 465),\n",
       " ('▁za', 466),\n",
       " ('】【', 467),\n",
       " ('le', 468),\n",
       " ('▁dan', 469),\n",
       " ('em', 470),\n",
       " ('á', 471),\n",
       " ('▁und', 472),\n",
       " ('al', 473),\n",
       " ('è', 474),\n",
       " ('▁10', 475),\n",
       " ('to', 476),\n",
       " ('ي', 477),\n",
       " ('E', 478),\n",
       " ('ka', 479),\n",
       " ('▁...', 480),\n",
       " ('w', 481),\n",
       " ('▁på', 482),\n",
       " (').', 483),\n",
       " ('ly', 484),\n",
       " ('▁po', 485),\n",
       " ('▁The', 486),\n",
       " ('7', 487),\n",
       " ('\":\"', 488),\n",
       " ('▁G', 489),\n",
       " ('T', 490),\n",
       " ('▁[', 491),\n",
       " ('la', 492),\n",
       " ('的', 493),\n",
       " ('li', 494),\n",
       " ('9', 495),\n",
       " ('▁ma', 496),\n",
       " ('▁0', 497),\n",
       " ('▁des', 498),\n",
       " ('▁med', 499),\n",
       " ('▁til', 500),\n",
       " ('▁La', 501),\n",
       " ('kan', 502),\n",
       " ('it', 503),\n",
       " ('▁ki', 504),\n",
       " ('no', 505),\n",
       " ('),', 506),\n",
       " ('м', 507),\n",
       " ('َ', 508),\n",
       " ('▁در', 509),\n",
       " ('▁so', 510),\n",
       " ('M', 511),\n",
       " ('▁som', 512),\n",
       " ('▁ke', 513),\n",
       " ('▁with', 514),\n",
       " ('▁F', 515),\n",
       " ('ni', 516),\n",
       " ('▁su', 517),\n",
       " ('▁και', 518),\n",
       " ('▁por', 519),\n",
       " ('▁les', 520),\n",
       " ('▁you', 521),\n",
       " ('si', 522),\n",
       " ('at', 523),\n",
       " ('ti', 524),\n",
       " ('id', 525),\n",
       " ('▁av', 526),\n",
       " ('▁as', 527),\n",
       " ('▁ya', 528),\n",
       " ('▁ve', 529),\n",
       " ('▁den', 530),\n",
       " ('▁R', 531),\n",
       " ('▁ב', 532),\n",
       " ('▁that', 533),\n",
       " ('▁tr', 534),\n",
       " ('は', 535),\n",
       " ('が', 536),\n",
       " ('do', 537),\n",
       " ('N', 538),\n",
       " ('ia', 539),\n",
       " ('\\\\', 540),\n",
       " ('ce', 541),\n",
       " ('▁om', 542),\n",
       " ('й', 543),\n",
       " ('▁се', 544),\n",
       " ('F', 545),\n",
       " ('&', 546),\n",
       " ('L', 547),\n",
       " ('▁م', 548),\n",
       " ('▁&', 549),\n",
       " ('▁د', 550),\n",
       " ('▁det', 551),\n",
       " ('▁от', 552),\n",
       " ('ó', 553),\n",
       " ('▁به', 554),\n",
       " ('▁pa', 555),\n",
       " ('▁من', 556),\n",
       " ('K', 557),\n",
       " ('на', 558),\n",
       " ('P', 559),\n",
       " ('▁ha', 560),\n",
       " ('V', 561),\n",
       " ('▁ch', 562),\n",
       " ('▁In', 563),\n",
       " ('▁W', 564),\n",
       " ('▁„', 565),\n",
       " ('I', 566),\n",
       " ('▁var', 567),\n",
       " ('▁ni', 568),\n",
       " ('se', 569),\n",
       " ('▁6', 570),\n",
       " ('ra', 571),\n",
       " ('ل', 572),\n",
       " ('▁una', 573),\n",
       " ('を', 574),\n",
       " ('▁في', 575),\n",
       " ('▁ta', 576),\n",
       " ('▁http', 577),\n",
       " ('COM', 578),\n",
       " ('am', 579),\n",
       " ('ה', 580),\n",
       " ('▁U', 581),\n",
       " ('R', 582),\n",
       " ('▁з', 583),\n",
       " ('▁re', 584),\n",
       " ('▁op', 585),\n",
       " ('ن', 586),\n",
       " ('т', 587),\n",
       " ('▁har', 588),\n",
       " ('ο', 589),\n",
       " ('H', 590),\n",
       " ('“', 591),\n",
       " ('ek', 592),\n",
       " ('▁ag', 593),\n",
       " ('▁ng', 594),\n",
       " ('▁los', 595),\n",
       " ('{', 596),\n",
       " ('▁och', 597),\n",
       " ('▁2017', 598),\n",
       " ('▁WWW', 599),\n",
       " ('に', 600),\n",
       " ('▁ku', 601),\n",
       " ('ir', 602),\n",
       " ('▁pe', 603),\n",
       " ('un', 604),\n",
       " ('х', 605),\n",
       " ('um', 606),\n",
       " ('▁2019', 607),\n",
       " ('je', 608),\n",
       " ('▁it', 609),\n",
       " ('▁до', 610),\n",
       " ('을', 611),\n",
       " ('ʻ', 612),\n",
       " ('www', 613),\n",
       " ('▁ب', 614),\n",
       " ('▁li', 615),\n",
       " ('но', 616),\n",
       " ('▁7', 617),\n",
       " ('▁»', 618),\n",
       " ('▁ir', 619),\n",
       " ('▁kan', 620),\n",
       " ('G', 621),\n",
       " ('▁het', 622),\n",
       " ('▁ho', 623),\n",
       " ('▁par', 624),\n",
       " ('▁vi', 625),\n",
       " ('・', 626),\n",
       " ('で', 627),\n",
       " ('▁20', 628),\n",
       " ('▁të', 629),\n",
       " ('▁8', 630),\n",
       " ('▁or', 631),\n",
       " ('ا', 632),\n",
       " ('م', 633),\n",
       " ('ie', 634),\n",
       " ('▁В', 635),\n",
       " ('ت', 636),\n",
       " ('ом', 637),\n",
       " ('W', 638),\n",
       " ('▁was', 639),\n",
       " ('την', 640),\n",
       " ('▁के', 641),\n",
       " ('▁En', 642),\n",
       " ('▁af', 643),\n",
       " ('▁12', 644),\n",
       " ('me', 645),\n",
       " ('O', 646),\n",
       " ('nya', 647),\n",
       " ('ma', 648),\n",
       " ('의', 649),\n",
       " ('ki', 650),\n",
       " ('▁cu', 651),\n",
       " ('μ', 652),\n",
       " ('▁No', 653),\n",
       " ('▁2016', 654),\n",
       " ('▁es', 655),\n",
       " ('▁een', 656),\n",
       " ('ки', 657),\n",
       " ('▁mi', 658),\n",
       " ('Ð', 659),\n",
       " ('10', 660),\n",
       " ('▁—', 661),\n",
       " ('ku', 662),\n",
       " ('\":', 663),\n",
       " ('▁J', 664),\n",
       " ('px', 665),\n",
       " ('일', 666),\n",
       " ('▁ל', 667),\n",
       " ('ни', 668),\n",
       " ('>', 669),\n",
       " ('▁15', 670),\n",
       " ('▁‘', 671),\n",
       " ('▁ver', 672),\n",
       " ('▁um', 673),\n",
       " ('▁man', 674),\n",
       " ('▁ko', 675),\n",
       " ('+', 676),\n",
       " ('▁nh', 677),\n",
       " ('η', 678),\n",
       " ('ка', 679),\n",
       " ('ny', 680),\n",
       " ('α', 681),\n",
       " ('▁od', 682),\n",
       " ('▁wa', 683),\n",
       " ('▁ge', 684),\n",
       " ('ов', 685),\n",
       " ('н', 686),\n",
       " ('ten', 687),\n",
       " ('▁С', 688),\n",
       " ('▁מ', 689),\n",
       " ('▁ph', 690),\n",
       " ('▁>', 691),\n",
       " ('▁men', 692),\n",
       " ('▁ber', 693),\n",
       " ('▁του', 694),\n",
       " ('▁از', 695),\n",
       " ('il', 696),\n",
       " ('ch', 697),\n",
       " ('▁bir', 698),\n",
       " ('▁το', 699),\n",
       " ('▁να', 700),\n",
       " ('el', 701),\n",
       " ('▁from', 702),\n",
       " ('▁nu', 703),\n",
       " ('ko', 704),\n",
       " ('st', 705),\n",
       " ('ë', 706),\n",
       " ('▁lo', 707),\n",
       " ('ủ', 708),\n",
       " ('▁az', 709),\n",
       " ('▁dem', 710),\n",
       " ('mi', 711),\n",
       " ('▁va', 712),\n",
       " ('▁att', 713),\n",
       " ('▁this', 714),\n",
       " ('ur', 715),\n",
       " ('▁nie', 716),\n",
       " ('#', 717),\n",
       " ('▁gi', 718),\n",
       " ('▁tu', 719),\n",
       " ('di', 720),\n",
       " ('å', 721),\n",
       " ('ات', 722),\n",
       " ('or', 723),\n",
       " ('▁em', 724),\n",
       " ('と', 725),\n",
       " ('ת', 726),\n",
       " ('▁Na', 727),\n",
       " ('▁am', 728),\n",
       " ('▁из', 729),\n",
       " ('▁11', 730),\n",
       " ('▁pro', 731),\n",
       " ('▁în', 732),\n",
       " ('▁30', 733),\n",
       " ('▁che', 734),\n",
       " ('для', 735),\n",
       " ('▁Z', 736),\n",
       " ('ru', 737),\n",
       " ('▁can', 738),\n",
       " ('ya', 739),\n",
       " ('▁ang', 740),\n",
       " ('ai', 741),\n",
       " ('▁f', 742),\n",
       " ('ga', 743),\n",
       " ('▁+', 744),\n",
       " ('za', 745),\n",
       " ('▁Se', 746),\n",
       " ('이', 747),\n",
       " ('ю', 748),\n",
       " ('▁mit', 749),\n",
       " ('ca', 750),\n",
       " ('▁all', 751),\n",
       " ('▁של', 752),\n",
       " ('ke', 753),\n",
       " ('\",', 754),\n",
       " ('°', 755),\n",
       " ('▁tak', 756),\n",
       " ('ने', 757),\n",
       " ('▁bu', 758),\n",
       " ('▁bo', 759),\n",
       " ('▁zu', 760),\n",
       " ('ą', 761),\n",
       " ('ή', 762),\n",
       " ('▁pour', 763),\n",
       " ('▁Le', 764),\n",
       " ('[', 765),\n",
       " ('▁ت', 766),\n",
       " ('▁ter', 767),\n",
       " ('▁با', 768),\n",
       " ('ci', 769),\n",
       " ('▁és', 770),\n",
       " ('co', 771),\n",
       " ('▁your', 772),\n",
       " ('om', 773),\n",
       " ('▁9', 774),\n",
       " ('▁کے', 775),\n",
       " ('▁not', 776),\n",
       " ('их', 777),\n",
       " ('▁к', 778),\n",
       " ('▁din', 779),\n",
       " ('im', 780),\n",
       " ('q', 781),\n",
       " ('ă', 782),\n",
       " ('▁have', 783),\n",
       " ('▁mai', 784),\n",
       " ('▁{', 785),\n",
       " ('▁pre', 786),\n",
       " ('▁we', 787),\n",
       " ('▁Re', 788),\n",
       " ('▁El', 789),\n",
       " ('▁he', 790),\n",
       " ('ς', 791),\n",
       " ('▁•', 792),\n",
       " ('và', 793),\n",
       " ('Y', 794),\n",
       " ('▁von', 795),\n",
       " ('▁là', 796),\n",
       " ('ې', 797),\n",
       " ('▁ar', 798),\n",
       " ('▁16', 799),\n",
       " ('▁las', 800),\n",
       " ('ú', 801),\n",
       " ('app', 802),\n",
       " ('▁کی', 803),\n",
       " ('▁au', 804),\n",
       " ('▁при', 805),\n",
       " ('U', 806),\n",
       " ('th', 807),\n",
       " ('▁}', 808),\n",
       " ('▁2014', 809),\n",
       " ('▁ba', 810),\n",
       " ('be', 811),\n",
       " ('▁18', 812),\n",
       " ('X', 813),\n",
       " ('▁2015', 814),\n",
       " ('▁2013', 815),\n",
       " ('▁(1)', 816),\n",
       " ('ой', 817),\n",
       " ('▁14', 818),\n",
       " ('▁qu', 819),\n",
       " ('ِ', 820),\n",
       " ('ha', 821),\n",
       " ('▁می', 822),\n",
       " ('man', 823),\n",
       " ('▁met', 824),\n",
       " ('are', 825),\n",
       " ('▁nga', 826),\n",
       " ('▁das', 827),\n",
       " ('▁της', 828),\n",
       " ('‘', 829),\n",
       " ('▁है', 830),\n",
       " ('ية', 831),\n",
       " ('то', 832),\n",
       " ('ь', 833),\n",
       " ('va', 834),\n",
       " ('ba', 835),\n",
       " ('】', 836),\n",
       " ('▁bi', 837),\n",
       " ('日', 838),\n",
       " ('한', 839),\n",
       " ('▁24', 840),\n",
       " ('ر', 841),\n",
       " ('ى', 842),\n",
       " ('▁est', 843),\n",
       " ('▁में', 844),\n",
       " ('lar', 845),\n",
       " ('▁2012', 846),\n",
       " ('▁dengan', 847),\n",
       " ('年', 848),\n",
       " ('▁13', 849),\n",
       " ('▁με', 850),\n",
       " ('▁untuk', 851),\n",
       " ('▁Y', 852),\n",
       " (');', 853),\n",
       " ('▁ini', 854),\n",
       " ('▁ש', 855),\n",
       " ('▁ist', 856),\n",
       " ('ve', 857),\n",
       " ('▁ا', 858),\n",
       " ('▁im', 859),\n",
       " ('this', 860),\n",
       " ('est', 861),\n",
       " ('▁online', 862),\n",
       " ('न', 863),\n",
       " ('▁А', 864),\n",
       " ('▁sur', 865),\n",
       " ('J', 866),\n",
       " ('▁У', 867),\n",
       " ('ך', 868),\n",
       " ('은', 869),\n",
       " ('ado', 870),\n",
       " ('▁ti', 871),\n",
       " ('ہ', 872),\n",
       " ('에', 873),\n",
       " ('ri', 874),\n",
       " ('▁för', 875),\n",
       " ('tu', 876),\n",
       " ('▁25', 877),\n",
       " ('lo', 878),\n",
       " ('」', 879),\n",
       " ('den', 880),\n",
       " ('%', 881),\n",
       " ('▁א', 882),\n",
       " ('د', 883),\n",
       " ('▁את', 884),\n",
       " ('▁có', 885),\n",
       " ('▁pas', 886),\n",
       " ('=\"', 887),\n",
       " ('▁ein', 888),\n",
       " ('ou', 889),\n",
       " ('▁mu', 890),\n",
       " ('月', 891),\n",
       " ('▁что', 892),\n",
       " ('ого', 893),\n",
       " ('*', 894),\n",
       " ('ի', 895),\n",
       " ('ים', 896),\n",
       " ('р', 897),\n",
       " ('▁will', 898),\n",
       " ('▁fa', 899),\n",
       " ('net', 900),\n",
       " ('▁για', 901),\n",
       " ('д', 902),\n",
       " ('ê', 903),\n",
       " ('▁*', 904),\n",
       " ('ُ', 905),\n",
       " ('ada', 906),\n",
       " ('▁qui', 907),\n",
       " ('ới', 908),\n",
       " ('г', 909),\n",
       " ('▁over', 910),\n",
       " ('▁17', 911),\n",
       " ('▁από', 912),\n",
       " ('ها', 913),\n",
       " (',\"', 914),\n",
       " ('ā', 915),\n",
       " ('▁را', 916),\n",
       " ('▁со', 917),\n",
       " ('та', 918),\n",
       " ('▁ser', 919),\n",
       " ('л', 920),\n",
       " ('que', 921),\n",
       " ('▁так', 922),\n",
       " ('▁про', 923),\n",
       " ('ể', 924),\n",
       " ('ok', 925),\n",
       " ('▁To', 926),\n",
       " ('▁σ', 927),\n",
       " ('▁და', 928),\n",
       " ('가', 929),\n",
       " ('ό', 930),\n",
       " ('ción', 931),\n",
       " ('ak', 932),\n",
       " ('ị', 933),\n",
       " ('▁که', 934),\n",
       " ('▁non', 935),\n",
       " ('ן', 936),\n",
       " ('▁је', 937),\n",
       " ('ro', 938),\n",
       " ('「', 939),\n",
       " ('ag', 940),\n",
       " ('ان', 941),\n",
       " ('على', 942),\n",
       " ('▁आ', 943),\n",
       " ('ите', 944),\n",
       " ('да', 945),\n",
       " ('с', 946),\n",
       " ('▁się', 947),\n",
       " ('▁€', 948),\n",
       " ('▁mo', 949),\n",
       " ('▁است', 950),\n",
       " ('▁·', 951),\n",
       " ('ý', 952),\n",
       " ('▁این', 953),\n",
       " ('Р', 954),\n",
       " ('▁if', 955),\n",
       " ('▁für', 956),\n",
       " ('не', 957),\n",
       " ('▁como', 958),\n",
       " ('▁X', 959),\n",
       " ('▁ca', 960),\n",
       " ('▁är', 961),\n",
       " ('ní', 962),\n",
       " ('▁19', 963),\n",
       " ('▁co', 964),\n",
       " ('▁כ', 965),\n",
       " ('▁100', 966),\n",
       " ('ere', 967),\n",
       " ('▁að', 968),\n",
       " ('wa', 969),\n",
       " ('▁cho', 970),\n",
       " ('▁voor', 971),\n",
       " ('▁2020', 972),\n",
       " ('▁میں', 973),\n",
       " ('و', 974),\n",
       " ('▁की', 975),\n",
       " ('ji', 976),\n",
       " ('▁Đ', 977),\n",
       " ('も', 978),\n",
       " ('▁pri', 979),\n",
       " ('▁este', 980),\n",
       " ('▁2011', 981),\n",
       " ('▁ce', 982),\n",
       " ('▁О', 983),\n",
       " ('▁է', 984),\n",
       " ('ik', 985),\n",
       " ('ት', 986),\n",
       " ('▁21', 987),\n",
       " ('는', 988),\n",
       " ('ку', 989),\n",
       " ('ж', 990),\n",
       " ('ے', 991),\n",
       " ('▁во', 992),\n",
       " ('ç', 993),\n",
       " ('ে', 994),\n",
       " ('п', 995),\n",
       " ('र', 996),\n",
       " ('Z', 997),\n",
       " ('▁од', 998),\n",
       " ('▁ob', 999),\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out list of tokens and their ids starting from 0\n",
    "# we see that utf8 is used to encode the tokens\n",
    "# since after 3 token then next 255 are bytes\n",
    "# and that it is a byte pair encoding algorithm\n",
    "sorted(tokenizer.vocab.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a425f1c58144d2946955f76efa709c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed0a900c3b6f472ab1c0c2bca6aa8dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5737fa87ae247c3a7e457f080d6fb39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/31.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d65b2b5a57914e0482ed85615f4523de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.71M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b2551d48fd4d269397134456a9da63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.79M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebf4adba4423410ab9fa3d738577ecad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96659fe5654460f91b82cdeaa961ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/18088 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8728d30fa5e04f7b81c500acb71c9be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492dbfd086464241a59164fad0e6585b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1019 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load dataset, asian language translation dataset\n",
    "# wanna look to find other datasets that coincide better with my language classifier\n",
    "# could probably use the flores dataset but only use specific languages so it doesnt fill my whole disk\n",
    "dataset = load_dataset('alt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into train validation and test\n",
    "train_dataset = dataset['train']\n",
    "validation_dataset = dataset['validation']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SNT.URLID': '80188',\n",
       " 'SNT.URLID.SNTID': '1',\n",
       " 'url': 'http://en.wikinews.org/wiki/2007_Rugby_World_Cup:_Italy_31_-_5_Portugal',\n",
       " 'translation': {'bg': 'ফ্রান্সের প্যারিসের পার্ক দি প্রিন্সেস-এ হওয়া ২০০৭-এর রাগবি বিশ্বকাপের পুল সি-তে ইটালি পর্তুগালকে ৩১-৫ গোলে হারিয়েছে।',\n",
       "  'en': 'Italy have defeated Portugal 31-5 in Pool C of the 2007 Rugby World Cup at Parc des Princes, Paris, France.',\n",
       "  'en_tok': 'Italy have defeated Portugal 31-5 in Pool C of the 2007 Rugby World Cup at Parc des Princes , Paris , France .',\n",
       "  'fil': 'Natalo ng Italya ang Portugal sa puntos na 31-5 sa Grupong C noong 2007 sa Pandaigdigang laro ng Ragbi sa Parc des Princes, Paris, France.',\n",
       "  'hi': '2007 में फ़्रांस, पेरिस के पार्क डेस प्रिंसेस में हुए रग्बी विश्व कप के पूल C में इटली ने पुर्तगाल को 31-5 से हराया।',\n",
       "  'id': 'Italia berhasil mengalahkan Portugal 31-5 di grup C dalam Piala Dunia Rugby 2007 di Parc des Princes, Paris, Perancis.',\n",
       "  'ja': 'フランスのパリ、パルク・デ・プランスで行われた2007年ラグビーワールドカップのプールCで、イタリアは31対5でポルトガルを下した。',\n",
       "  'khm': 'អ៊ីតាលីបានឈ្នះលើព័រទុយហ្គាល់ 31-5 ក្នុងប៉ូលCនៃពីធីប្រកួតពានរង្វាន់ពិភពលោកនៃកីឡាបាល់ឱបឆ្នាំ2007ដែលប្រព្រឹត្តនៅប៉ាសឌេសប្រីន ក្រុងប៉ារីស បារាំង។',\n",
       "  'lo': 'ອິຕາລີໄດ້ເສຍໃຫ້ປ໊ອກຕຸຍການ 31 ຕໍ່ 5 ໃນພູລ C ຂອງ ການແຂ່ງຂັນຣັກບີ້ລະດັບໂລກປີ 2007 ທີ່ ປາກເດແພຣັງ ປາຣີ ປະເທດຝຣັ່ງ.',\n",
       "  'ms': 'Itali telah mengalahkan Portugal 31-5 dalam Pool C pada Piala Dunia Ragbi 2007 di Parc des Princes, Paris, Perancis.',\n",
       "  'my': 'ပြင်သစ်နိုင်ငံ ပါရီမြို့ ပါ့ဒက်စ် ပရင့်စက် ၌ ၂၀၀၇ခုနှစ် ရပ်ဘီ ကမ္ဘာ့ ဖလား တွင် အီတလီ သည် ပေါ်တူဂီ ကို ၃၁-၅ ဂိုး ဖြင့် ရေကူးကန် စီ တွင် ရှုံးနိမ့်သွားပါသည် ။',\n",
       "  'th': 'อิตาลีได้เอาชนะโปรตุเกสด้วยคะแนน31ต่อ5 ในกลุ่มc ของการแข่งขันรักบี้เวิลด์คัพปี2007 ที่สนามปาร์กเดแพร็งส์ ที่กรุงปารีส ประเทศฝรั่งเศส',\n",
       "  'vi': 'Ý đã đánh bại Bồ Đào Nha với tỉ số 31-5 ở Bảng C Giải vô địch Rugby thế giới 2007 tại Parc des Princes, Pari, Pháp.',\n",
       "  'zh': '意大利在法国巴黎王子公园体育场举办的2007年橄榄球世界杯C组以31-5击败葡萄牙。'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at the dataset\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bg': 'ফ্রান্সের প্যারিসের পার্ক দি প্রিন্সেস-এ হওয়া ২০০৭-এর রাগবি বিশ্বকাপের পুল সি-তে ইটালি পর্তুগালকে ৩১-৫ গোলে হারিয়েছে।',\n",
       " 'en': 'Italy have defeated Portugal 31-5 in Pool C of the 2007 Rugby World Cup at Parc des Princes, Paris, France.',\n",
       " 'en_tok': 'Italy have defeated Portugal 31-5 in Pool C of the 2007 Rugby World Cup at Parc des Princes , Paris , France .',\n",
       " 'fil': 'Natalo ng Italya ang Portugal sa puntos na 31-5 sa Grupong C noong 2007 sa Pandaigdigang laro ng Ragbi sa Parc des Princes, Paris, France.',\n",
       " 'hi': '2007 में फ़्रांस, पेरिस के पार्क डेस प्रिंसेस में हुए रग्बी विश्व कप के पूल C में इटली ने पुर्तगाल को 31-5 से हराया।',\n",
       " 'id': 'Italia berhasil mengalahkan Portugal 31-5 di grup C dalam Piala Dunia Rugby 2007 di Parc des Princes, Paris, Perancis.',\n",
       " 'ja': 'フランスのパリ、パルク・デ・プランスで行われた2007年ラグビーワールドカップのプールCで、イタリアは31対5でポルトガルを下した。',\n",
       " 'khm': 'អ៊ីតាលីបានឈ្នះលើព័រទុយហ្គាល់ 31-5 ក្នុងប៉ូលCនៃពីធីប្រកួតពានរង្វាន់ពិភពលោកនៃកីឡាបាល់ឱបឆ្នាំ2007ដែលប្រព្រឹត្តនៅប៉ាសឌេសប្រីន ក្រុងប៉ារីស បារាំង។',\n",
       " 'lo': 'ອິຕາລີໄດ້ເສຍໃຫ້ປ໊ອກຕຸຍການ 31 ຕໍ່ 5 ໃນພູລ C ຂອງ ການແຂ່ງຂັນຣັກບີ້ລະດັບໂລກປີ 2007 ທີ່ ປາກເດແພຣັງ ປາຣີ ປະເທດຝຣັ່ງ.',\n",
       " 'ms': 'Itali telah mengalahkan Portugal 31-5 dalam Pool C pada Piala Dunia Ragbi 2007 di Parc des Princes, Paris, Perancis.',\n",
       " 'my': 'ပြင်သစ်နိုင်ငံ ပါရီမြို့ ပါ့ဒက်စ် ပရင့်စက် ၌ ၂၀၀၇ခုနှစ် ရပ်ဘီ ကမ္ဘာ့ ဖလား တွင် အီတလီ သည် ပေါ်တူဂီ ကို ၃၁-၅ ဂိုး ဖြင့် ရေကူးကန် စီ တွင် ရှုံးနိမ့်သွားပါသည် ။',\n",
       " 'th': 'อิตาลีได้เอาชนะโปรตุเกสด้วยคะแนน31ต่อ5 ในกลุ่มc ของการแข่งขันรักบี้เวิลด์คัพปี2007 ที่สนามปาร์กเดแพร็งส์ ที่กรุงปารีส ประเทศฝรั่งเศส',\n",
       " 'vi': 'Ý đã đánh bại Bồ Đào Nha với tỉ số 31-5 ở Bảng C Giải vô địch Rugby thế giới 2007 tại Parc des Princes, Pari, Pháp.',\n",
       " 'zh': '意大利在法国巴黎王子公园体育场举办的2007年橄榄球世界杯C组以31-5击败葡萄牙。'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just a dictionary of the translation no misc data\n",
    "train_dataset[0]['translation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(250105, 512)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add language token mapping to the tokenizer\n",
    "LANG_TOKEN_MAPPING = {\n",
    "    'en' : '<en>',\n",
    "    'fil' : '<fil>',\n",
    "    'hi' : '<hi>',\n",
    "    'id' : '<id>',\n",
    "    'ja' : '<ja>', \n",
    "}\n",
    "# create a dict of the dict\n",
    "special_tokens = { 'additional_special_tokens': list(LANG_TOKEN_MAPPING.values()) }\n",
    "# add special tokens to the tokenizer\n",
    "tokenizer.add_special_tokens(special_tokens)\n",
    "# resize the token embeddings layer to correct size\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  714,   339,   259,   262,   259, 98923,   305,   609,   339,   259,\n",
      "          4940,   259, 26866,  2421,   609,  3609,   390,   510,   787,   738,\n",
      "          4245,  1350,   259,  3245,     1,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "# padding test\n",
    "max_seq_length = 50\n",
    "input_str = 'this is a sentence and it is really longer than it should be so we can check out padding'\n",
    "# tokenize the sentence with padding\n",
    "token_ids = tokenizer.encode(\n",
    "    input_str, return_tensors='pt', padding='max_length', \n",
    "    truncation=True, max_length=max_seq_length\n",
    ")\n",
    "# show the tokenized sentence\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizes and numericalizes input string\n",
    "def encode_input_str(text, target_lang, tokenizer, seq_len,\n",
    "                     lang_token_map=LANG_TOKEN_MAPPING):\n",
    "  target_lang_token = lang_token_map[target_lang]\n",
    "\n",
    "  # Tokenize and add special tokens\n",
    "  input_ids = tokenizer.encode(\n",
    "      text = target_lang_token + text,\n",
    "      return_tensors = 'pt',\n",
    "      padding = 'max_length',\n",
    "      truncation = True,\n",
    "      max_length = seq_len)\n",
    "\n",
    "  return input_ids[0]\n",
    "\n",
    "# tokenizes and numericalizes target string\n",
    "def encode_target_str(text, tokenizer, seq_len):\n",
    "  token_ids = tokenizer.encode(\n",
    "      text = text,\n",
    "      return_tensors = 'pt',\n",
    "      padding = 'max_length',\n",
    "      truncation = True,\n",
    "      max_length = seq_len)\n",
    "  \n",
    "  return token_ids[0]\n",
    "\n",
    "# improvement would be do this for all permutations of languages \n",
    "# or at least more than once per example\n",
    "def format_translation_data(translations, lang_token_map,\n",
    "                            tokenizer, seq_length=20):\n",
    "  # choose 2 random languages for i/o\n",
    "  langs = list(lang_token_map.keys())\n",
    "  input_lang, target_lang = np.random.choice(langs, size=2, replace=False)\n",
    "  input_text = translations[input_lang]\n",
    "  target_text = translations[target_lang]\n",
    "  \n",
    "  if input_text is None or target_text is None:\n",
    "    return None, None\n",
    "  \n",
    "  input_ids = encode_input_str(input_text, target_lang, tokenizer, seq_length, \n",
    "                                lang_token_map)\n",
    "  \n",
    "  target_ids = encode_target_str(target_text, tokenizer, seq_length)\n",
    "  \n",
    "  return input_ids, target_ids\n",
    "\n",
    "\n",
    "def transform_batch(batch, lang_token_map, tokenizer, seq_length=20):\n",
    "  input_ids = []\n",
    "  target_ids = []\n",
    "  \n",
    "  for example in batch['translation']:\n",
    "      input_id, target_id = format_translation_data(example, lang_token_map, tokenizer)\n",
    "      \n",
    "      if input_id is not None:\n",
    "          input_ids.append(input_id)\n",
    "          target_ids.append(target_id)\n",
    "  \n",
    "  input_ids = torch.stack(input_ids).cuda()\n",
    "  target_ids = torch.stack(target_ids).cuda()\n",
    "  \n",
    "  return input_ids, target_ids\n",
    "\n",
    "# generator function\n",
    "def get_data_generator(dataset, lang_token_map, tokenizer, batch_size=32):\n",
    "  dataset = dataset.shuffle()\n",
    "  \n",
    "  for i in range(0, len(dataset), batch_size):\n",
    "      batch = dataset[i:i+batch_size]\n",
    "      yield transform_batch(batch, lang_token_map, tokenizer)\n",
    "\n",
    "def get_dataloader(dataset, lang_token_map, tokenizer, batch_size=32):\n",
    "  dataset = dataset.shuffle()\n",
    "  dataset = dataset.map(lambda batch: transform_batch(batch, lang_token_map, tokenizer), batched=True)\n",
    "  dataset.set_format(type='torch', columns=['input_ids', 'target_ids'])\n",
    "  data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n",
    "  \n",
    "  return data_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar to above but for all permutations of languages\n",
    "def get_all_translation_data(translations, lang_token_map,\n",
    "                            tokenizer, seq_length=20):\n",
    "  input_ids = []\n",
    "  target_ids = []\n",
    "  \n",
    "  langs = list(lang_token_map.keys())\n",
    "  for input_lang, target_lang in itertools.permutations(langs, 2):\n",
    "    input_text = translations[input_lang]\n",
    "    target_text = translations[target_lang]\n",
    "    \n",
    "    if input_text is None or target_text is None:\n",
    "        return None, None\n",
    "    \n",
    "    input_ids.append(encode_input_str(input_text, target_lang, tokenizer, seq_length, \n",
    "                                    lang_token_map))\n",
    "    \n",
    "    target_ids.append(encode_target_str(target_text, tokenizer, seq_length))\n",
    "  \n",
    "  return input_ids, target_ids\n",
    "\n",
    "# generator function\n",
    "def get_full_dataloader(dataset, lang_token_map, tokenizer, batch_size=32, num_workers=8):\n",
    "    # get translations from the dataset\n",
    "    dataset = train_dataset['translation']\n",
    "    # intialize array\n",
    "    data = []\n",
    "    for example in dataset:\n",
    "        # get translations for all permuations of languages\n",
    "        input_id, target_id = get_all_translation_data(example, lang_token_map, tokenizer)\n",
    "        # case where nothing is returned\n",
    "        if input_id is None or target_id is None:\n",
    "            continue\n",
    "        # add the list of target and inputs \n",
    "        list_of_dicts = list(map(lambda x, y: {'input_ids': x, 'target_ids': y}, input_id, target_id))\n",
    "        data = data + list_of_dicts\n",
    "    # load dataset into a dataloader\n",
    "    loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    # return the dataloader\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get generator for all permutations of languages for each example\n",
    "data_gen = get_full_data_generator(train_dataset, LANG_TOKEN_MAPPING, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 20]) torch.Size([20, 20])\n"
     ]
    }
   ],
   "source": [
    "# get first batch and check the shape\n",
    "batch = next(data_gen)\n",
    "print(batch[0].shape, batch[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<hi> ▁Natal o ▁ng ▁Italy a ▁ang ▁Portugal ▁sa ▁punto s ▁na ▁3 1-5 ▁sa ▁ Grupo ng ▁C </s>\n",
      "▁2007 ▁में ▁फ़ ्रा ंस , ▁पे रिस ▁के ▁पार् क ▁डे स ▁ प्रि ंस ेस ▁में ▁हु </s>\n"
     ]
    }
   ],
   "source": [
    "# convert the translation data of first data point to input and output tensors\n",
    "input_ids, output_ids = format_translation_data(train_dataset[0]['translation'], LANG_TOKEN_MAPPING, tokenizer)\n",
    "# print out decoded input and output tensors\n",
    "print(' '.join(tokenizer.convert_ids_to_tokens(input_ids)))\n",
    "print(' '.join(tokenizer.convert_ids_to_tokens(output_ids)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 20])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "data_gen = get_data_generator(train_dataset, LANG_TOKEN_MAPPING, tokenizer, 8)\n",
    "batch = next(data_gen)\n",
    "print(batch[0].shape)\n",
    "print(len(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "EPOCHS = 5\n",
    "batch_size = 64\n",
    "learning_rate = 5e-3\n",
    "n_batches = np.ceil(len(train_dataset) / batch_size)\n",
    "total_steps = n_batches * EPOCHS\n",
    "print_freq = total_steps / 100\n",
    "checkpoint_freq = total_steps / 10\n",
    "n_warmup_steps = int(0.01 * total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "schedular = get_linear_schedule_with_warmup(optimizer, n_warmup_steps, total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, gdataset, max_iters=8):\n",
    "  test_generator = get_data_generator(gdataset, LANG_TOKEN_MAPPING,\n",
    "                                      tokenizer, batch_size)\n",
    "  eval_losses = []\n",
    "  for i, (input_batch, label_batch) in enumerate(test_generator):\n",
    "    if i >= max_iters:\n",
    "      break\n",
    "\n",
    "    model_out = model.forward(\n",
    "        input_ids = input_batch,\n",
    "        labels = label_batch)\n",
    "    eval_losses.append(model_out.loss.item())\n",
    "\n",
    "  return np.mean(eval_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "1000it [01:47,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 999/18088, Loss: 11.23216724395752, LR: 1.1061946902654867e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2001it [03:36,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 1999/18088, Loss: 6.367169380187988, LR: 2.2123893805309735e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [05:24,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 2999/18088, Loss: 5.103701591491699, LR: 3.3185840707964604e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4000it [07:12,  8.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 3999/18088, Loss: 4.362479209899902, LR: 4.424778761061947e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4999it [09:00,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 4999/18088, Loss: 3.627501964569092, LR: 5.5309734513274336e-05\n",
      "Saving model with test loss of 3.820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6001it [10:51,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 5999/18088, Loss: 3.5280957221984863, LR: 6.637168141592921e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7000it [12:39,  8.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 6999/18088, Loss: 3.173626661300659, LR: 7.743362831858407e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8000it [14:27,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 7999/18088, Loss: 3.1209208965301514, LR: 8.849557522123894e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9000it [16:15,  8.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 8999/18088, Loss: 2.636758327484131, LR: 9.955752212389381e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9999it [18:03,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 9999/18088, Loss: 2.6385674476623535, LR: 0.00011061946902654867\n",
      "Saving model with test loss of 2.795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11000it [19:53,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 10999/18088, Loss: 2.781362771987915, LR: 0.00012168141592920354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11302it [20:26,  9.21it/s]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "1002it [01:48,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 999/18088, Loss: 2.5065481662750244, LR: 0.00013274336283185842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [03:36,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 1999/18088, Loss: 2.5226550102233887, LR: 0.0001438053097345133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [05:24,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 2999/18088, Loss: 2.4258015155792236, LR: 0.00015486725663716813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4001it [07:12,  9.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 3999/18088, Loss: 2.2852673530578613, LR: 0.00016592920353982303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4999it [09:01,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 4999/18088, Loss: 2.2574713230133057, LR: 0.00017699115044247788\n",
      "Saving model with test loss of 2.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6000it [10:51,  8.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 5999/18088, Loss: 1.968928337097168, LR: 0.00018805309734513275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7000it [12:39,  8.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 6999/18088, Loss: 1.9487088918685913, LR: 0.00019911504424778762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7899it [14:17,  9.33it/s]"
     ]
    }
   ],
   "source": [
    "loss_i = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Randomize data order, need to figure out a faster way to do this\n",
    "    loader = get_full_dataloader(train_dataset, LANG_TOKEN_MAPPING, tokenizer, batch_size, num_workers=8)\n",
    "    \n",
    "    for i, batch in tqdm.tqdm(enumerate(loader), total = n_batches):\n",
    "        inputs, targets = batch['input_ids'].cuda(), batch['target_ids'].cuda()\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass (computes outputs and loss)\n",
    "        output = model(input_ids=inputs, labels=targets)\n",
    "        loss = output.loss\n",
    "        # Back propagation (computes gradients)\n",
    "        loss.backward()\n",
    "        # Optimization and scheduling\n",
    "        optimizer.step()\n",
    "        # Adjust every 100 batches\n",
    "        if(i+1) % 500 == 0:\n",
    "            loss_i.append(loss.item())\n",
    "            schedular.step()\n",
    "        # prints training updates\n",
    "        if (i+1) % print_freq == 0:\n",
    "            print(f'Epoch: {epoch + 1}, Batch: {i+1}/{n_batches}, Loss: {loss.item()}, LR: {schedular.get_last_lr()[0]}')\n",
    "        \n",
    "        if (i + 1) % checkpoint_freq == 0:\n",
    "            test_loss = eval_model(model, test_dataset)\n",
    "            print('Saving model with test loss of {:.3f}'.format(test_loss))\n",
    "            torch.save(model.state_dict(), 'mt5_translator.pt')\n",
    "torch.save(model.state_dict(), 'mt5_translator_final.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f37b68c4890>]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sentence: Randwick has been locked down, and is expected to remain so for up to two months.\n",
      "Truncated input: <ja> Randwick has been locked down, and is expected to remain so for up</s>\n"
     ]
    }
   ],
   "source": [
    "# Get a test sentence\n",
    "test_sentence = test_dataset[1]['translation']['en']\n",
    "print(f\"Test sentence: {test_sentence}\")\n",
    "# Tokenize and encode the test sentence\n",
    "input_ids = encode_input_str(test_sentence, 'ja', tokenizer, model.config.max_length, LANG_TOKEN_MAPPING)\n",
    "input_ids = input_ids.unsqueeze(0).cuda()\n",
    "# print out the tokenized sentence of max length\n",
    "print(\"Truncated input:\", tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ランダーウィックが倒壊したと予想されている。\n",
      "ランダーウィックが倒壊したと予想されているが、現在、その地域は\n",
      "ランダーウィックが倒壊したと予想されているが、その時点では、この\n"
     ]
    }
   ],
   "source": [
    "# convert to new language\n",
    "output = model.generate(input_ids, num_beams = 10, num_return_sequences = 3)\n",
    "for token_set in output:\n",
    "    print(tokenizer.decode(token_set, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_translation_data(translations, lang_token_map,\n",
    "                            tokenizer, seq_length=20):\n",
    "  input_ids = []\n",
    "  target_ids = []\n",
    "  \n",
    "  langs = list(lang_token_map.keys())\n",
    "  for input_lang, target_lang in itertools.permutations(langs, 2):\n",
    "    input_text = translations[input_lang]\n",
    "    target_text = translations[target_lang]\n",
    "    \n",
    "    if input_text is None or target_text is None:\n",
    "        return None, None\n",
    "    \n",
    "    input_ids.append(encode_input_str(input_text, target_lang, tokenizer, seq_length, \n",
    "                                    lang_token_map))\n",
    "    \n",
    "    target_ids.append(encode_target_str(target_text, tokenizer, seq_length))\n",
    "  \n",
    "  return input_ids, target_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = get_all_translation_data(train_dataset[0]['translation'], LANG_TOKEN_MAPPING, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = []\n",
    "c = c + a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([250100,  20161,    783,    269,  62956,    345,  15772,    381,  62482,\n",
       "            281,  23577,    371,    304,    287,   1848,    259,  93887,   4025,\n",
       "          10291,      1]),\n",
       " tensor([250102,  20161,    783,    269,  62956,    345,  15772,    381,  62482,\n",
       "            281,  23577,    371,    304,    287,   1848,    259,  93887,   4025,\n",
       "          10291,      1]),\n",
       " tensor([250103,  20161,    783,    269,  62956,    345,  15772,    381,  62482,\n",
       "            281,  23577,    371,    304,    287,   1848,    259,  93887,   4025,\n",
       "          10291,      1]),\n",
       " tensor([250104,  20161,    783,    269,  62956,    345,  15772,    381,  62482,\n",
       "            281,  23577,    371,    304,    287,   1848,    259,  93887,   4025,\n",
       "          10291,      1]),\n",
       " tensor([250101,  33756,    268,    594,  20161,    262,    740,  15772,    327,\n",
       "           8218,    263,    294,    381,  62482,    327,    259,  37503,    370,\n",
       "            371,      1]),\n",
       " tensor([250102,  33756,    268,    594,  20161,    262,    740,  15772,    327,\n",
       "           8218,    263,    294,    381,  62482,    327,    259,  37503,    370,\n",
       "            371,      1]),\n",
       " tensor([250103,  33756,    268,    594,  20161,    262,    740,  15772,    327,\n",
       "           8218,    263,    294,    381,  62482,    327,    259,  37503,    370,\n",
       "            371,      1]),\n",
       " tensor([250104,  33756,    268,    594,  20161,    262,    740,  15772,    327,\n",
       "           8218,    263,    294,    381,  62482,    327,    259,  37503,    370,\n",
       "            371,      1]),\n",
       " tensor([250101,   1848,    844,  46739,  81794,  25488,    261,  21799, 102577,\n",
       "            641,  78910,   1650,  31417,   2312,    259, 132205,  25488,  48242,\n",
       "            844,      1]),\n",
       " tensor([250100,   1848,    844,  46739,  81794,  25488,    261,  21799, 102577,\n",
       "            641,  78910,   1650,  31417,   2312,    259, 132205,  25488,  48242,\n",
       "            844,      1]),\n",
       " tensor([250103,   1848,    844,  46739,  81794,  25488,    261,  21799, 102577,\n",
       "            641,  78910,   1650,  31417,   2312,    259, 132205,  25488,  48242,\n",
       "            844,      1]),\n",
       " tensor([250104,   1848,    844,  46739,  81794,  25488,    261,  21799, 102577,\n",
       "            641,  78910,   1650,  31417,   2312,    259, 132205,  25488,  48242,\n",
       "            844,      1]),\n",
       " tensor([250101,   7444,    693,   6950,  10612,  43440,  15772,    381,  62482,\n",
       "            301,   4958,    371,   1215,  21475,    492,    259,  38316,    259,\n",
       "          93887,      1]),\n",
       " tensor([250100,   7444,    693,   6950,  10612,  43440,  15772,    381,  62482,\n",
       "            301,   4958,    371,   1215,  21475,    492,    259,  38316,    259,\n",
       "          93887,      1]),\n",
       " tensor([250102,   7444,    693,   6950,  10612,  43440,  15772,    381,  62482,\n",
       "            301,   4958,    371,   1215,  21475,    492,    259,  38316,    259,\n",
       "          93887,      1]),\n",
       " tensor([250104,   7444,    693,   6950,  10612,  43440,  15772,    381,  62482,\n",
       "            301,   4958,    371,   1215,  21475,    492,    259,  38316,    259,\n",
       "          93887,      1]),\n",
       " tensor([250101,    259,  75179,    423,  85757,    292, 123213,   6662,    626,\n",
       "          13532,    626,  36350,   3144,    627, 231749,  17774,    848, 221756,\n",
       "         118058,      1]),\n",
       " tensor([250100,    259,  75179,    423,  85757,    292, 123213,   6662,    626,\n",
       "          13532,    626,  36350,   3144,    627, 231749,  17774,    848, 221756,\n",
       "         118058,      1]),\n",
       " tensor([250102,    259,  75179,    423,  85757,    292, 123213,   6662,    626,\n",
       "          13532,    626,  36350,   3144,    627, 231749,  17774,    848, 221756,\n",
       "         118058,      1]),\n",
       " tensor([250103,    259,  75179,    423,  85757,    292, 123213,   6662,    626,\n",
       "          13532,    626,  36350,   3144,    627, 231749,  17774,    848, 221756,\n",
       "         118058,      1])]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en fil\n",
      "en hi\n",
      "en id\n",
      "en ja\n",
      "fil en\n",
      "fil hi\n",
      "fil id\n",
      "fil ja\n",
      "hi en\n",
      "hi fil\n",
      "hi id\n",
      "hi ja\n",
      "id en\n",
      "id fil\n",
      "id hi\n",
      "id ja\n",
      "ja en\n",
      "ja fil\n",
      "ja hi\n",
      "ja id\n"
     ]
    }
   ],
   "source": [
    "# choose 2 random languages for i/o\n",
    "langs = list(LANG_TOKEN_MAPPING.keys())\n",
    "for input_lang, target_lang in itertools.permutations(langs, 2):\n",
    "  print(input_lang, target_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ja> ▁Italia ▁ber hasil ▁menga lahkan ▁Portugal ▁3 1-5 ▁di ▁grup ▁C ▁dalam ▁Pia la ▁ Dunia ▁ Rugby </s>\n",
      "▁ フランス の パリ 、 パル ク ・ デ ・ プラン ス で 行われた 2007 年 ラグビー ワールド カップ </s>\n"
     ]
    }
   ],
   "source": [
    "# convert the translation data of first data point to input and output tensors\n",
    "input_ids, output_ids = format_translation_data(train_dataset[0]['translation'], LANG_TOKEN_MAPPING, tokenizer)\n",
    "# print out decoded input and output tensors\n",
    "print(' '.join(tokenizer.convert_ids_to_tokens(input_ids)))\n",
    "print(' '.join(tokenizer.convert_ids_to_tokens(output_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
